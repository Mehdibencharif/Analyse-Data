import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO
from datetime import timedelta
import re
import hashlib
import unicodedata
from pandas.api.types import is_numeric_dtype

# ----------------------------- Constantes / placeholders -----------------------------

# Valeurs considÃ©rÃ©es comme "vides" ou "nulles"
PLACEHOLDER_NULLS = {"", " ", "-", "â€”", "â€“", "NA", "N/A", "na", "n/a", "null", "None"}

# Motif pour reconnaÃ®tre les colonnes de tempÃ©rature
TEMP_NAME_RE = re.compile(r"(?i)(temp|temperature|Â°\s*c|degc|degre|Â°c|\[Â°c\])")

# ----------------------------- Utilitaires "qualitÃ© data" -----------------------------

def series_with_true_nans(s: pd.Series) -> pd.Series:
    """Transforme les placeholders en vrais NaN pour bien compter les manquants."""
    if s.dtype == object:
        s = s.astype(str).str.strip()
        s = s.replace(list(PLACEHOLDER_NULLS), pd.NA)
        s = s.replace(r"^\s+$", pd.NA, regex=True)
    return s

def coerce_numeric_general(df: pd.DataFrame, threshold: float = 0.6) -> pd.DataFrame:
    """
    Force les colonnes majoritairement numÃ©riques en float.
    Les placeholders ou textes parasites deviennent NaN.
    """
    df = df.copy()
    for col in df.columns:
        if str(col).lower() in ("timestamp", "notes"):
            continue

        s = df[col]
        if not is_numeric_dtype(s):
            s2 = series_with_true_nans(s).astype(str).str.replace(",", ".", regex=False).str.strip()
            numeric = pd.to_numeric(s2, errors="coerce")

            # si la majoritÃ© est numÃ©rique, on conserve
            if numeric.notna().mean() >= threshold:
                df[col] = numeric

    return df

def coerce_temperature_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Convertit les colonnes de tempÃ©rature en float (NaN si non numÃ©rique)."""
    df = df.copy()
    for col in df.columns:
        if str(col).lower() in ("timestamp", "notes"):
            continue

        if TEMP_NAME_RE.search(str(col)):
            s = series_with_true_nans(df[col])
            s = s.astype(str).str.replace(",", ".", regex=False).str.strip()
            df[col] = pd.to_numeric(s, errors="coerce")

    return df

def stats_min_max_mean(df: pd.DataFrame) -> pd.DataFrame:
    """
    Calcule min / max / moyenne pour chaque capteur numÃ©rique (hors timestamp/notes).
    Retourne un DataFrame stable, mÃªme si df est vide.
    """
    cols_out = ["Capteur", "Min", "Max", "Moyenne", "Nb valeurs", "Nb manquantes", "% prÃ©sentes"]
    if df is None or not isinstance(df, pd.DataFrame) or df.empty:
        return pd.DataFrame(columns=cols_out)

    rows = []
    total = len(df)

    for col in df.columns:
        c = str(col).lower()
        if c in ("timestamp", "notes"):
            continue

        s = series_with_true_nans(df[col])

        # forcer en numÃ©rique (si Ã§a ne convertit pas -> tout NaN)
        s_num = pd.to_numeric(
            s.astype(str).str.replace(",", ".", regex=False).str.strip(),
            errors="coerce"
        )

        nb_val = int(s_num.notna().sum())
        nb_nan = int(total - nb_val)
        pct = (100.0 * nb_val / total) if total > 0 else 0.0

        rows.append({
            "Capteur": str(col),
            "Min": float(s_num.min()) if nb_val > 0 else None,
            "Max": float(s_num.max()) if nb_val > 0 else None,
            "Moyenne": float(s_num.mean()) if nb_val > 0 else None,
            "Nb valeurs": nb_val,
            "Nb manquantes": nb_nan,
            "% prÃ©sentes": round(pct, 2),
        })

    return pd.DataFrame(rows, columns=cols_out)
#----- Bloc 2 -------------#

# ----------------------------- Streamlit : page & paramÃ¨tres -----------------------------

st.set_page_config(page_title="Analyse de donnÃ©es capteurs", layout="wide")
st.title("ğŸ“Š Analyse de donnÃ©es capteurs")

# =========================
# ParamÃ¨tres d'analyse
# =========================
st.sidebar.header("ParamÃ¨tres d'analyse")

frequence = st.sidebar.selectbox(
    "Choisissez la frÃ©quence d'analyse :",
    ["1min", "5min", "10min", "15min", "1H"],
    index=3  # 15 min par dÃ©faut (tu peux changer)
)

rule_map = {
    "1min": "1min",
    "5min": "5min",
    "10min": "10min",
    "15min": "15min",
    "1H": "1H"
}

# =========================
# TÃ©lÃ©versement des fichiers
# =========================
st.sidebar.subheader("TÃ©lÃ©versement des fichiers")

main_file = st.sidebar.file_uploader(
    "ğŸ“‚ Fichier principal (obligatoire)",
    type=["xlsx", "xls", "xlsm"],
    key="main"
)

compare_file = st.sidebar.file_uploader(
    "ğŸ“‚ Fichier de comparaison (facultatif)",
    type=["xlsx", "xls", "xlsm"],
    key="compare"
)

# =========================
# Hash & reset d'Ã©tat (sÃ©lection feuille) si fichier change
# =========================
def file_sha1(uploaded) -> str:
    data = uploaded.getvalue() if uploaded is not None else b""
    return hashlib.sha1(data).hexdigest()[:10]

if main_file is not None:
    st.sidebar.caption(f"Hash fichier principal : `{file_sha1(main_file)}`")
if compare_file is not None:
    st.sidebar.caption(f"Hash fichier comparaison : `{file_sha1(compare_file)}`")

if "last_main_sha1" not in st.session_state:
    st.session_state["last_main_sha1"] = None

curr_sha1 = file_sha1(main_file) if main_file is not None else None

if curr_sha1 is not None and curr_sha1 != st.session_state["last_main_sha1"]:
    # On oublie les sÃ©lections de feuilles liÃ©es Ã  l'ancien fichier
    for k in list(st.session_state.keys()):
        if str(k).startswith("Fichier principal_sheet_"):
            del st.session_state[k]

    st.session_state["last_main_sha1"] = curr_sha1
    
#----- Bloc 3 -------------#
# ----------------------------- Chargement fichier -----------------------------

def charger_fichier_excel(fichier, nom_fichier: str) -> pd.DataFrame:
    """
    Charge un fichier Excel uploadÃ© (Streamlit) et retourne un DataFrame
    avec une colonne 'timestamp' (colonne 0 renommÃ©e), triÃ©e et nettoyÃ©e.
    """
    raw = fichier.getvalue()
    xls = pd.ExcelFile(BytesIO(raw))

    # clÃ© UI unique (Ã©vite les conflits quand on change de fichier)
    sheet_key = f"{nom_fichier}_sheet_{hashlib.sha1(raw).hexdigest()[:8]}"

    # sÃ©lection de la feuille si plusieurs
    if len(xls.sheet_names) == 1:
        feuille = xls.sheet_names[0]
    else:
        feuille = st.selectbox(
            f"ğŸ“„ Feuille Ã  utiliser pour {nom_fichier}",
            xls.sheet_names,
            key=sheet_key
        )

    df = pd.read_excel(xls, sheet_name=feuille)

    # nettoyage des noms de colonnes
    df.columns = [str(c).strip() for c in df.columns]

    # sÃ©curitÃ© : au moins 1 colonne
    if df.shape[1] < 1:
        return pd.DataFrame()

    # 1Ã¨re colonne = timestamp
    first_col = df.columns[0]
    if str(first_col).lower() != "timestamp":
        df = df.rename(columns={first_col: "timestamp"})

    # parsing timestamp
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")

    # nettoyage
    df = df.dropna(subset=["timestamp"]).sort_values("timestamp").reset_index(drop=True)

    return df

# --- Stop si pas de fichier principal
if main_file is None:
    st.warning("âš ï¸ Veuillez tÃ©lÃ©verser un fichier principal pour dÃ©marrer lâ€™analyse.")
    st.stop()

# ----------------------------- Filtre temporel (sidebar) -----------------------------
st.sidebar.subheader("Filtre temporel (optionnel)")
date_deb = st.sidebar.date_input("DÃ©but", value=None)
date_fin = st.sidebar.date_input("Fin", value=None)

def filtrer_periode(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if df.empty:
        return df

    if date_deb is not None:
        df = df[df["timestamp"] >= pd.Timestamp(date_deb)]

    if date_fin is not None:
        # inclut toute la journÃ©e de date_fin
        df = df[df["timestamp"] < (pd.Timestamp(date_fin) + pd.Timedelta(days=1))]

    return df

# ----------------------------- Chargement + conversions + filtre -----------------------------

df_main = charger_fichier_excel(main_file, "Fichier principal")

# sÃ©curitÃ© : fichier vide ou mal lu
if df_main is None or df_main.empty:
    st.warning("âš ï¸ Aucune donnÃ©e lue dans le fichier (ou feuille vide).")
    st.stop()

# sÃ©curitÃ© : timestamp obligatoire
if "timestamp" not in df_main.columns:
    st.error("âŒ Colonne 'timestamp' introuvable (la 1Ã¨re colonne devrait Ãªtre un temps/date).")
    st.stop()

# conversions (temp d'abord, puis gÃ©nÃ©ral)
df_main = coerce_temperature_columns(df_main)
df_main = coerce_numeric_general(df_main)

# re-sÃ©curise timestamp (au cas oÃ¹)
df_main["timestamp"] = pd.to_datetime(df_main["timestamp"], errors="coerce")
df_main = df_main.dropna(subset=["timestamp"])

# filtre pÃ©riode
df_main = filtrer_periode(df_main)

# affichage pÃ©riode + pas dÃ©tectÃ©
if not df_main.empty:
    tmin = df_main["timestamp"].min()
    tmax = df_main["timestamp"].max()
    st.sidebar.caption(f"PÃ©riode dÃ©tectÃ©e : {tmin} â†’ {tmax}")

    # dÃ©tection pas (protÃ©gÃ©e)
    try:
        step_info = detect_sampling_step(df_main, "timestamp")
    except NameError:
        step_info = {"median_min": None, "mode_min": None, "summary": None}
        st.sidebar.error("âŒ detect_sampling_step() n'est pas dÃ©fini. Mets la fonction dans le bloc 1, avant cet appel.")
    except Exception as e:
        step_info = {"median_min": None, "mode_min": None, "summary": None}
        st.sidebar.error(f"âŒ Erreur dÃ©tection pas : {e}")

    if step_info.get("median_min") is not None:
        st.sidebar.success(
            f"â±ï¸ Pas dÃ©tectÃ© (mÃ©dian) : {step_info['median_min']:.2f} min\n"
            f"ğŸ“Œ Pas le + frÃ©quent : {step_info['mode_min']:.2f} min"
        )
        if step_info.get("summary"):
            st.sidebar.caption(f"Top pas : {step_info['summary']}")
    else:
        st.sidebar.warning("â±ï¸ Pas de remontÃ©e non dÃ©tectable (timestamps insuffisants ou irrÃ©guliers).")

else:
    st.warning("âš ï¸ Aucune donnÃ©e valide aprÃ¨s chargement/filtrage.")
    st.stop()

#----- Bloc 4 -------------#
# ----------------------------- Nettoyage noms (comparaison) -----------------------------

def nettoyer_nom_capteur(nom: str) -> str:
    """
    Supprime les unitÃ©s entre crochets [] ou parenthÃ¨ses () et les espaces inutiles.
    Exemples :
      'Temp-1 [Â°C]'      -> 'Temp-1'
      'DÃ©bit (Gpm)'      -> 'DÃ©bit'
      'Pression [bar] '  -> 'Pression'
    """
    s = str(nom)
    s = re.sub(r"\s*[\[\(].*?[\]\)]", "", s)  # enlÃ¨ve [ ... ] ou ( ... )
    s = re.sub(r"\s+", " ", s)                # normalise les espaces
    return s.strip()

# Colonnes nettoyÃ©es (sauf timestamp)
df_main_cleaned = df_main.copy()
df_main_cleaned.columns = [
    "timestamp" if str(c).lower() == "timestamp" else nettoyer_nom_capteur(c)
    for c in df_main_cleaned.columns
]

# ----------------------------- Fichier de rÃ©fÃ©rence (facultatif) -----------------------------

df_compare = None
capteurs_reference_cleaned = set()

if compare_file is not None:
    try:
        raw_ref = BytesIO(compare_file.getvalue())

        # Feuille: si plusieurs, on laisse l'utilisateur choisir
        xls_ref = pd.ExcelFile(raw_ref)
        if len(xls_ref.sheet_names) == 1:
            ref_sheet = xls_ref.sheet_names[0]
        else:
            ref_sheet = st.sidebar.selectbox(
                "ğŸ“„ Feuille Ã  utiliser pour le fichier de comparaison",
                xls_ref.sheet_names,
                key="compare_sheet_select"
            )

        df_compare = pd.read_excel(xls_ref, sheet_name=ref_sheet)

        if "Description" not in df_compare.columns:
            st.error("âŒ Le fichier de comparaison doit contenir une colonne 'Description'.")
            st.stop()

        df_compare["Description"] = df_compare["Description"].astype(str).str.strip()

        # Ensemble des capteurs de rÃ©fÃ©rence (nettoyÃ©s)
        capteurs_reference_cleaned = {
            nettoyer_nom_capteur(c) for c in df_compare["Description"].dropna().tolist()
        }

        st.success(f"âœ… Fichier de comparaison chargÃ© ({len(capteurs_reference_cleaned)} capteurs).")

    except Exception as e:
        st.error(f"âŒ Erreur lors de la lecture du fichier de comparaison : {e}")
        st.stop()
else:
    st.info("â„¹ï¸ Aucun fichier de comparaison n'a Ã©tÃ© tÃ©lÃ©versÃ© (facultatif).")

#----- Bloc 5 -------------#
# ----------------------------- Analyse simple -----------------------------

def analyse_simplifiee(df: pd.DataFrame) -> pd.DataFrame:
    st.subheader("PrÃ©sentes vs Manquantes â€“ MÃ©thode simple")

    if df is None or df.empty:
        st.info("Aucune donnÃ©e Ã  analyser.")
        return pd.DataFrame(columns=["Capteur", "PrÃ©sentes", "% PrÃ©sentes", "Manquantes", "% Manquantes", "Statut", "Nom_nettoye"])

    total = len(df)
    resume = []

    for col in df.columns:
        if str(col).lower() in ("timestamp", "notes"):
            continue

        # placeholders -> vrais NaN
        s = series_with_true_nans(df[col])

        presente = int(s.notna().sum())
        manquantes = int(total - presente)

        pct_presente = (100.0 * presente / total) if total > 0 else 0.0
        pct_manquantes = 100.0 - pct_presente

        statut = "ğŸŸ¢" if pct_presente >= 80 else ("ğŸŸ " if pct_presente > 0 else "ğŸ”´")

        resume.append({
            "Capteur": str(col).strip(),
            "PrÃ©sentes": presente,
            "% PrÃ©sentes": round(pct_presente, 2),
            "Manquantes": manquantes,
            "% Manquantes": round(pct_manquantes, 2),
            "Statut": statut
        })

    df_resume = pd.DataFrame(resume)

    # nom nettoyÃ© (sert pour doublons + comparaison)
    df_resume["Nom_nettoye"] = df_resume["Capteur"].astype(str).apply(nettoyer_nom_capteur)

    st.dataframe(df_resume, use_container_width=True)
    return df_resume

# âœ… Utiliser df_main_cleaned pour Ãªtre cohÃ©rent avec les noms nettoyÃ©s
df_simple = analyse_simplifiee(df_main_cleaned)

# ----------------------------- Doublons (basÃ© sur nom nettoyÃ©) -----------------------------

df_simple["Doublon"] = df_simple["Nom_nettoye"].duplicated(keep=False).map({True: "ğŸ” Oui", False: "âœ… Non"})
df_simple = df_simple.drop_duplicates(subset=["Nom_nettoye"], keep="last").reset_index(drop=True)

# ----------------------------- Validation vs rÃ©fÃ©rence (si fournie) -----------------------------

df_valides = pd.DataFrame()
df_non_valides = pd.DataFrame()
df_manquants = pd.DataFrame()

if isinstance(capteurs_reference_cleaned, set) and len(capteurs_reference_cleaned) > 0:
    df_simple["Dans la rÃ©fÃ©rence"] = df_simple["Nom_nettoye"].isin(capteurs_reference_cleaned).map(
        {True: "âœ… Oui", False: "âŒ Non"}
    )

    # trier: capteurs reconnus en haut
    df_simple = df_simple.sort_values(by="Dans la rÃ©fÃ©rence", ascending=False).reset_index(drop=True)

    st.subheader("âœ… Capteurs trouvÃ©s dans la rÃ©fÃ©rence")
    df_valides = df_simple[df_simple["Dans la rÃ©fÃ©rence"] == "âœ… Oui"]
    if not df_valides.empty:
        st.dataframe(df_valides[["Capteur", "Dans la rÃ©fÃ©rence", "Doublon"]], use_container_width=True)
    else:
        st.write("Aucun capteur valide trouvÃ©.")

    st.subheader("âŒ Capteurs absents de la rÃ©fÃ©rence")
    df_non_valides = df_simple[df_simple["Dans la rÃ©fÃ©rence"] == "âŒ Non"]
    if not df_non_valides.empty:
        st.dataframe(df_non_valides[["Capteur", "Dans la rÃ©fÃ©rence", "Doublon"]], use_container_width=True)
        st.subheader("Liste brute â€“ Capteurs absents de la rÃ©fÃ©rence")
        st.write(df_non_valides["Capteur"].tolist())
    else:
        st.write("Tous les capteurs sont prÃ©sents dans la rÃ©fÃ©rence.")

    # capteurs attendus mais absents des donnÃ©es
    capteurs_trouves = set(df_simple["Nom_nettoye"].dropna().tolist())
    manquants = sorted(capteurs_reference_cleaned - capteurs_trouves)

    if manquants:
        st.subheader("Capteurs attendus non trouvÃ©s dans les donnÃ©es analysÃ©es")
        df_manquants = pd.DataFrame(manquants, columns=["Capteur (rÃ©fÃ©rence manquant dans les donnÃ©es)"])
        st.dataframe(df_manquants, use_container_width=True)
    else:
        st.write("âœ… Tous les capteurs attendus sont prÃ©sents dans les donnÃ©es.")

#----- Bloc 6 -------------#
# ----------------------------- Resample (utile pour d'autres vues, pas pour la complÃ©tude) -----------------------------

def resampler_df(df: pd.DataFrame, frequence_str: str, rule_map: dict) -> pd.DataFrame:
    """
    RÃ©Ã©chantillonne les DONNÃ‰ES (valeurs) selon la frÃ©quence choisie.
    âš ï¸ Ã€ ne pas utiliser pour calculer la complÃ©tude (utiliser analyser_completude_freq).
    """
    if df is None or df.empty:
        st.info("Aucune donnÃ©e Ã  rÃ©Ã©chantillonner.")
        return pd.DataFrame()

    if "timestamp" not in df.columns:
        st.warning("âš ï¸ Colonne 'timestamp' non trouvÃ©e dans le fichier.")
        return df.copy()

    if frequence_str not in rule_map:
        st.warning("âš ï¸ FrÃ©quence invalide.")
        return df.copy()

    st.info(f"â±ï¸ FrÃ©quence sÃ©lectionnÃ©e : {frequence_str}")

    try:
        df2 = df.copy()
        df2["timestamp"] = pd.to_datetime(df2["timestamp"], errors="coerce")
        df2 = df2.dropna(subset=["timestamp"]).sort_values("timestamp")

        # pas de resample si 1min
        if frequence_str == "1min":
            st.info("âœ… Pas de rÃ©Ã©chantillonnage nÃ©cessaire (1min).")
            return df2.reset_index(drop=True)

        freq = rule_map[frequence_str]

        # index temporel
        df2 = df2.set_index("timestamp")

        # mapping d'agrÃ©gation
        agg_map = {}
        for col in df2.columns:
            c = str(col).lower()
            if c == "notes":
                agg_map[col] = "first"
            else:
                agg_map[col] = "mean" if is_numeric_dtype(df2[col]) else "first"

        df_resampled = df2.resample(freq).agg(agg_map).reset_index()

        st.success(f"âœ… DonnÃ©es rÃ©Ã©chantillonnÃ©es avec succÃ¨s Ã  {frequence_str}.")
        return df_resampled

    except Exception as e:
        st.error(f"âŒ Erreur lors du rÃ©Ã©chantillonnage : {e}")
        return df.reset_index(drop=True) if isinstance(df.index, pd.RangeIndex) else df.reset_index()


# ----------------------------- Nouvelle complÃ©tude (INDICATEUR) -----------------------------

def build_presence_indicator(df: pd.DataFrame) -> pd.DataFrame:
    """
    CrÃ©e un indicateur de prÃ©sence (1 = prÃ©sent, NaN = manquant)
    pour toutes les colonnes sauf timestamp/notes, Ã  partir des donnÃ©es BRUTES.
    """
    cols = [c for c in df.columns if str(c).lower() not in ("timestamp", "notes")]
    ind = pd.DataFrame(index=df.index)

    for c in cols:
        s = series_with_true_nans(df[c])
        ind[c] = s.notna().astype("float")  # 1.0 = prÃ©sent, NaN = manquant

    return ind


def analyser_completude_freq(df: pd.DataFrame, frequence_str: str, rule_map: dict) -> pd.DataFrame:
    """
    Calcule la complÃ©tude Ã  partir d'un indicateur de prÃ©sence.
    Retourne TOUJOURS un DataFrame.
    """
    base_cols = ["Capteur", "PrÃ©sentes", "% PrÃ©sentes", "Manquantes", "% Manquantes", "Statut"]

    # âœ… debug visible (tu peux enlever aprÃ¨s)
    # st.caption("DEBUG: analyser_completude_freq() appelÃ©e")

    # garde-fous
    if df is None or not isinstance(df, pd.DataFrame) or df.empty:
        return pd.DataFrame(columns=base_cols)

    if "timestamp" not in df.columns:
        st.error("âŒ La colonne 'timestamp' est manquante.")
        return pd.DataFrame(columns=base_cols)

    df2 = df.copy()
    df2["timestamp"] = pd.to_datetime(df2["timestamp"], errors="coerce")
    df2 = df2.dropna(subset=["timestamp"]).sort_values("timestamp").reset_index(drop=True)

    if df2.empty:
        return pd.DataFrame(columns=base_cols)

    ind = build_presence_indicator(df2)
    ind.index = df2["timestamp"]

    if frequence_str != "1min":
        if frequence_str not in rule_map:
            st.error("âŒ FrÃ©quence invalide.")
            return pd.DataFrame(columns=base_cols)

        freq = rule_map[frequence_str]
        ind_bin = ind.resample(freq).max()  # bin prÃ©sent si au moins une valeur
        total_expected = float(len(ind_bin.index))
        if total_expected == 0:
            return pd.DataFrame(columns=base_cols)

        total_present = ind_bin.fillna(0).sum(axis=0)
    else:
        total_expected = float(len(ind))
        if total_expected == 0:
            return pd.DataFrame(columns=base_cols)

        total_present = ind.fillna(0).sum(axis=0)

    rows = []
    for c in ind.columns:
        pres = float(total_present.get(c, 0.0))
        pct = 100.0 * pres / total_expected
        statut = "ğŸŸ¢" if pct >= 80 else ("ğŸŸ " if pct > 0 else "ğŸ”´")

        rows.append({
            "Capteur": str(c),
            "PrÃ©sentes": int(round(pres)),
            "% PrÃ©sentes": round(pct, 2),
            "Manquantes": int(round(total_expected - pres)),
            "% Manquantes": round(100.0 - pct, 2),
            "Statut": statut
        })

    return pd.DataFrame(rows, columns=base_cols)

#----- Bloc 7 -------------#
st.subheader(f"ğŸ“ˆ Analyse de complÃ©tude des donnÃ©es brutes ({frequence})")

# 1) Calcul complÃ©tude
stats_main = analyser_completude_freq(df_main_cleaned, frequence, rule_map)

st.write("DEBUG type stats_main:", type(stats_main))
st.write("DEBUG colonnes stats_main:", list(stats_main.columns) if isinstance(stats_main, pd.DataFrame) else stats_main)

# 2) SÃ©curitÃ©s AVANT manip
if stats_main is None or not isinstance(stats_main, pd.DataFrame):
    st.error("â›” analyser_completude_freq() n'a pas retournÃ© un DataFrame (stats_main est None ou invalide).")
    st.stop()

expected_cols = ["Capteur", "PrÃ©sentes", "% PrÃ©sentes", "Manquantes", "% Manquantes", "Statut"]
missing = [c for c in expected_cols if c not in stats_main.columns]
if missing:
    st.error(f"â›” Colonnes manquantes dans stats_main : {missing} | Colonnes trouvÃ©es : {list(stats_main.columns)}")
    st.stop()

# 3) Si vide : on affiche, mais on ne stop pas forcÃ©ment (tu peux choisir)
if stats_main.empty:
    st.warning("âš ï¸ RÃ©sultat complÃ©tude vide (aucun capteur ou aucune donnÃ©e exploitable).")
    st.dataframe(stats_main, use_container_width=True)
else:
    # Nettoyage capteur + dÃ©dup
    stats_main["Capteur"] = stats_main["Capteur"].astype(str).str.strip()
    stats_main = stats_main.drop_duplicates(subset=["Capteur"], keep="last").reset_index(drop=True)
    st.dataframe(stats_main, use_container_width=True)

# ----------------------------- LÃ©gende + RÃ©sumÃ© -----------------------------
st.markdown("""
### ğŸ§¾ LÃ©gende des statuts :
- ğŸŸ¢ : Capteur exploitable (â‰¥80 % de valeurs prÃ©sentes)
- ğŸŸ  : Incomplet (entre 1 % et 79 %)
- ğŸ”´ : DonnÃ©es absentes (0 %)
""")

if not stats_main.empty:
    count_vert = int(stats_main["Statut"].value_counts().get("ğŸŸ¢", 0))
    count_orange = int(stats_main["Statut"].value_counts().get("ğŸŸ ", 0))
    count_rouge = int(stats_main["Statut"].value_counts().get("ğŸ”´", 0))

    st.markdown(f"""
**RÃ©sumÃ© des capteurs :**
- Capteurs exploitables (ğŸŸ¢) : `{count_vert}`
- Capteurs incomplets (ğŸŸ ) : `{count_orange}`
- Capteurs vides (ğŸ”´) : `{count_rouge}`
""")

# sanity-check
st.caption(f"â±ï¸ Lignes analysÃ©es : {len(df_main)}")
st.caption(
    f"ğŸ§® Colonnes (hors timestamp/notes) : "
    f"{len([c for c in df_main.columns if str(c).lower() not in ('timestamp','notes')])}"
)

# ----------------------------- Statistiques valeurs (min/max/moyenne) -----------------------------
st.subheader("ğŸ“Œ Statistiques des valeurs (min / max / moyenne)")

try:
    df_stats_values = stats_min_max_mean(df_main_cleaned)  # nÃ©cessite la fonction ajoutÃ©e dans le bloc utilitaires
except Exception as e:
    st.error(f"âŒ Erreur stats_min_max_mean : {e}")
    df_stats_values = pd.DataFrame(columns=["Capteur", "Min", "Max", "Moyenne", "Nb valeurs", "Nb manquantes", "% prÃ©sentes"])

st.dataframe(df_stats_values, use_container_width=True)

# ----------------------------- Graphique complÃ©tude (barh) -----------------------------
st.subheader("ğŸ“Š Graphique â€” ComplÃ©tude des capteurs")

if stats_main.empty:
    st.info("Aucun graphique : stats_main est vide.")
else:
    df_plot = stats_main.sort_values(by="% PrÃ©sentes", ascending=True).copy()

    fig, ax = plt.subplots(figsize=(10, max(6, len(df_plot) * 0.25)))
    ax.barh(df_plot["Capteur"], df_plot["% PrÃ©sentes"])
    ax.set_title("ComplÃ©tude des capteurs")
    ax.set_xlabel("% DonnÃ©es prÃ©sentes")
    ax.set_ylabel("Capteur")
    ax.set_xlim(0, 100)
    ax.grid(True, axis="x", alpha=0.3)
    plt.tight_layout()
    st.pyplot(fig)

# ----------------------------- Export Excel -----------------------------
st.subheader("ğŸ“¤ Export des rÃ©sultats (Excel)")

# âœ… SÃ©curiser step_info : sâ€™il nâ€™existe pas, on le recalcule ici
if "step_info" not in locals() or not isinstance(step_info, dict):
    step_info = detect_sampling_step(df_main, "timestamp")

# âœ… SÃ©curiser df_simple : sâ€™il nâ€™existe pas / vide, on crÃ©e un DF minimal
if "df_simple" not in locals() or not isinstance(df_simple, pd.DataFrame) or df_simple.empty:
    df_simple = pd.DataFrame(columns=["Capteur", "PrÃ©sentes", "% PrÃ©sentes", "Manquantes", "% Manquantes", "Statut", "Nom_nettoye", "Doublon"])

output = BytesIO()

with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
    # Feuille 1 : rÃ©sumÃ© simple
    df_simple.to_excel(writer, index=False, sheet_name="RÃ©sumÃ© capteurs")

    # Feuille 2 : complÃ©tude brute
    stats_main.to_excel(writer, index=False, sheet_name="ComplÃ©tude brute")

    # Feuille 3 : stats valeurs
    df_stats_values.to_excel(writer, index=False, sheet_name="Stats valeurs")

    # Feuille 4 : info pas
    df_step = pd.DataFrame([{
        "Pas mÃ©dian": str(step_info.get("median")),
        "Pas mÃ©dian (min)": step_info.get("median_min"),
        "Pas le + frÃ©quent": str(step_info.get("mode")),
        "Pas le + frÃ©quent (min)": step_info.get("mode_min"),
        "Top pas (count)": step_info.get("summary"),
        "FrÃ©quence choisie (analyse)": frequence
    }])
    df_step.to_excel(writer, index=False, sheet_name="Info pas")

    # Feuilles optionnelles
    if "df_non_valides" in locals() and isinstance(df_non_valides, pd.DataFrame) and not df_non_valides.empty:
        df_non_valides.to_excel(writer, index=False, sheet_name="Capteurs non reconnus")

    if "df_manquants" in locals() and isinstance(df_manquants, pd.DataFrame) and not df_manquants.empty:
        df_manquants.to_excel(writer, index=False, sheet_name="Capteurs manquants")

    # Mise en forme conditionnelle (si colonne Statut existe)
    workbook = writer.book
    format_vert = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})
    format_orange = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C5700'})
    format_rouge = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})

    feuille = writer.sheets["RÃ©sumÃ© capteurs"]

    if "Statut" in df_simple.columns:
        statut_col = df_simple.columns.get_loc("Statut")
        last_row = max(1, len(df_simple))  # Ã©vite 0

        feuille.conditional_format(1, statut_col, last_row, statut_col, {
            'type': 'text', 'criteria': 'containing', 'value': 'ğŸŸ¢', 'format': format_vert
        })
        feuille.conditional_format(1, statut_col, last_row, statut_col, {
            'type': 'text', 'criteria': 'containing', 'value': 'ğŸŸ ', 'format': format_orange
        })
        feuille.conditional_format(1, statut_col, last_row, statut_col, {
            'type': 'text', 'criteria': 'containing', 'value': 'ğŸ”´', 'format': format_rouge
        })

output.seek(0)

st.download_button(
    label="ğŸ“¥ TÃ©lÃ©charger le rapport Excel",
    data=output,
    file_name="rapport_capteurs.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)











